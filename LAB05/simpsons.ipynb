{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{},"colab_type":"code","id":"r5uZAfmgSQ1j"},"outputs":[],"source":["import sys\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","import cv2\n","import matplotlib.pyplot as plt\n","from glob import glob\n","import os \n","from os.path import join\n","\n","from tensorflow.keras.layers import Flatten, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.preprocessing import image_dataset_from_directory\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.applications.vgg16 import preprocess_input\n","from tensorflow.keras.applications.resnet import preprocess_input"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def get_images_and_labels(directory):\n","    os.chdir(directory)\n","    \n","    images = []\n","    images_names = []\n","    class_images = []\n","\n","    images_names = glob('*.bmp')\n","\n","    for img in images_names:\n","        #separação do label da classe\n","        label = img.split('0')[0]\n","        label = label.split('1')[0]\n","        class_images.append(label)\n","        \n","        #abertura da imagem\n","        pathfile = join(directory, img)\n","        temporary = cv2.imread(pathfile, cv2.IMREAD_UNCHANGED)\n","        images.append(temporary)\n","\n","    \n","    return images, images_names, class_images"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def segmentation(list_image):\n","    #list_images está em BGR\n","\n","    bgr_list = []\n","    for img in list_image:\n","        simpson = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        simpson_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n","        \n","        light_yellow = (0, 70, 110)\n","        dark_yellow = (130, 255, 255)\n","        mask = cv2.inRange(simpson_hsv, light_yellow, dark_yellow)\n","\n","        result_rbg = cv2.bitwise_and(simpson, simpson, mask=mask)\n","        \n","        result_bgr = cv2.cvtColor(result_rbg, cv2.COLOR_RGB2BGR)\n","\n","        bgr_list.append(result_bgr)\n","\n","    return bgr_list"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def generate_hist(list_image, dimensions, equalize=False):\n","    histogram_list = []\n","\n","    for img in list_image:\n","        img = cv2.resize(img, dimensions, interpolation=cv2.INTER_AREA)\n","\n","        if (equalize == True):\n","            # convert from RGB color-space to YCrCb\n","            ycrcb_img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n","\n","            # equalize the histogram of the Y channel\n","            ycrcb_img[:, :, 0] = cv2.equalizeHist(ycrcb_img[:, :, 0])\n","\n","            # convert back to RGB color-space from YCrCb\n","            img = cv2.cvtColor(ycrcb_img, cv2.COLOR_YCrCb2BGR)\n","            \n","\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","        histogram = cv2.calcHist([img], [0,1,2], None, [8,8,8], [0, 256, 0, 256, 0, 256])\n","        cv2.normalize(histogram, histogram, 0, 255, cv2.NORM_MINMAX)\n","        histogram = histogram.flatten()\n","\n","        histogram_list.append(histogram)\n","        \n","    return histogram_list"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def calcHuMoments(img):\n","\timg = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","\tret,th = cv2.threshold(img,128,255,cv2.THRESH_BINARY_INV)\n","\tmoment = cv2.moments(th)\n","\thuMoment = cv2.HuMoments(moment)\n","\n","\treturn map(lambda hu: -1 * np.sign(hu) * np.log10(np.abs(hu)), huMoment)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def generate_hu_moments(list_image):\n","    hu_moments_list = []\n","\n","    for img in list_image:\n","        huMoment = calcHuMoments(img)\n","        huMoment = list(huMoment)\n","        huMoment = np.concatenate(huMoment, axis=0)\n","        temporary = np.array(huMoment)\n","                \n","        hu_moments_list.append(temporary[:3])\n","        \n","    return hu_moments_list"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def generate_vec_from_cnn(name, base_dir):\n","    ## PARÂMETROS\n","    img_rows, img_cols = 224, 224\n","    input_shape = (img_rows, img_cols, 3)\n","\n","    #Batch size\n","    batch_size = 32\n","\n","    nome_base = 'simpsons'\n","\n","    path_train = join(base_dir, nome_base, 'train')\n","    path_test = join(base_dir, nome_base, 'test')\n","\n","\n","    #Carregamento da Base de Dados\n","    train_dataset = image_dataset_from_directory(\n","        path_train,\n","        image_size=(img_rows, img_cols),\n","        color_mode=\"rgb\",\n","        batch_size=batch_size,\n","        shuffle=False)\n","    test_dataset = image_dataset_from_directory(\n","        path_test,\n","        image_size=(img_rows, img_cols),\n","        color_mode=\"rgb\",\n","        batch_size=batch_size,\n","        shuffle=False)\n","    \n","    #OTIMIZAÇÃO\n","    AUTOTUNE = tf.data.AUTOTUNE\n","    train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n","    test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n","    \n","\n","\n","    if (name == 'vgg'):\n","        vgg16 = VGG16()\n","\n","        vgg16_top_false =  VGG16(include_top=False, input_shape=(224,224,3))\n","\n","        cnn = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n","        inputs = keras.Input(shape=input_shape)\n","        x = preprocess_input(inputs)\n","        x = cnn(x)\n","        output = Flatten()(x)\n","        model = Model(inputs, output)\n","    \n","    \n","    elif (name == 'resnet50'):\n","        resnet50 = ResNet50()\n","\n","        resnet50_top_false =  ResNet50(include_top=False, input_shape=(224,224,3))\n","\n","        cnn = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n","        inputs = keras.Input(shape=input_shape)\n","        x = preprocess_input(inputs)\n","        x = cnn(x)\n","        output = GlobalAveragePooling2D()(x)\n","        model = Model(inputs, output)\n","    \n","\n","    X_train = model.predict(train_dataset)\n","    X_test = model.predict(test_dataset)\n","\n","    # y_train = np.concatenate([y for x, y in train_dataset], axis=0)\n","    # y_test = np.concatenate([y for x, y in test_dataset], axis=0)\n","\n","    return X_train, X_test"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def classification(t_cmp, v_cmp, t_images, v_images, t_classes, v_classes, method):\n","    classification_count, final_count = 0, 0\n","\n","    for v_index, validation in enumerate(v_cmp):\n","        temp_list = []\n","\n","        for _, compare in enumerate(t_cmp):\n","            #cálculo da distância euclidiana entre as duas entradas\n","            distance = np.linalg.norm(validation-compare)\n","            temp_list.append(distance)\n","        \n","        min_value = min(temp_list)\n","        min_index = temp_list.index(min_value)\n","\n","\n","        if (v_classes[v_index] == t_classes[min_index]):\n","            classification_count += 1\n","            classification_result = \"(ACERTO)\"\n","        else:\n","            classification_result = \"(ERRO)\"\n","\n","\n","        final_count += 1\n","        print(f\"{v_images[v_index]} - {t_images[min_index]} -- {classification_result}\")\n","\n","    accuracy = classification_count / final_count\n","    print( \"\\n\")\n","    print(f\"-->Nome do Método = {method}\")\n","    print( \"-->Classificações CORRETAS = {}\".format(classification_count) )\n","    print( \"-->Total de IMAGENS = {}\".format(final_count) )\n","    print( \"-->Acurácia = {0:1.3f}\".format(accuracy) )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if __name__ == \"__main__\":\n","    #DEFINIÇÕES INICIAIS\n","    dimensions = (450,500)\n","    base_dir = os.getcwd()\n","    print(base_dir)\n","\n","    #Leitura do caminho do treino\n","    train_path = sys.argv[1]\n","    print(train_path)\n","\n","    #Leitura do caminho da validação\n","    valid_path = sys.argv[2]\n","    print(valid_path)\n","\n","    #Leitura das imagens\n","    os.chdir(base_dir)\n","    train_images, train_names, train_classes = get_images_and_labels(train_path)\n","    valid_images, valid_names, valid_classes = get_images_and_labels(valid_path)\n","    os.chdir(base_dir)\n","\n","    #Segmentação das imagens\n","    train_images_seg = segmentation(train_images)\n","    valid_images_seg = segmentation(valid_images)\n","\n","    if (len(sys.argv) == 4):\n","        if sys.argv[3] == \"m02\": ##histogramas sem equalização\n","            print(\"--------- METODOLOGIA BASEADA EM COMPARAÇÃO DE HISTOGRAMAS ---------\")\n","            train_histogram = generate_hist(train_images, dimensions, equalize=False)\n","            valid_histogram = generate_hist(valid_images, dimensions, equalize=False)\n","            classification(train_histogram, valid_histogram, train_names, valid_names, train_classes, valid_classes, \"Classificação de Histogramas (sem equalização)\")\n","\n","        elif sys.argv[3] == \"m03\": ##histogramas sem equalização e com segmentação de imagem\n","            print(\"--------- METODOLOGIA BASEADA EM COMPARAÇÃO DE HISTOGRAMAS ---------\")\n","            train_histogram = generate_hist(train_images_seg, dimensions, equalize=False)\n","            valid_histogram = generate_hist(valid_images_seg, dimensions, equalize=False)\n","            classification(train_histogram, valid_histogram, train_names, valid_names, train_classes, valid_classes, \"Classificação de Histogramas (sem equalização e com segmentação de imagem)\")\n","\n","        elif sys.argv[3] == \"m04\": ##momentos de hu sem segmentação\n","            print(\"--------- METODOLOGIA BASEADA EM COMPARAÇÃO DE MOMENTOS DE HU ---------\")\n","            train_moments = generate_hu_moments(train_images)\n","            valid_moments = generate_hu_moments(valid_images)\n","            classification(train_moments, valid_moments, train_names, valid_names, train_classes, valid_classes, \"Classificação de Momentos de HU (sem segmentação)\")\n","\n","        elif sys.argv[3] == \"m05\": ##momentos de hu com segmentação\n","            print(\"--------- METODOLOGIA BASEADA EM COMPARAÇÃO DE MOMENTOS DE HU ---------\")\n","            train_moments = generate_hu_moments(train_images_seg)\n","            valid_moments = generate_hu_moments(valid_images_seg)\n","            classification(train_moments, valid_moments, train_names, valid_names, train_classes, valid_classes, \"Classificação de Momentos de HU (com segmentação)\")\n","\n","        elif sys.argv[3] == \"m06\": ##vgg como extrator de característica\n","            print(\"--------- METODOLOGIA BASEADA EM EXTRAÇÃO COM VGG16 ---------\")\n","            train_vectors, valid_vectors = generate_vec_from_cnn('vgg', base_dir)\n","            classification(train_vectors, valid_vectors, train_names, valid_names, train_classes, valid_classes, \"Classificação utilizando VGG16 para extração de CARACTERÍSTICAS\")\n","\n","        elif sys.argv[3] == \"m07\": ##resnet5 como extrator de característica\n","            print(\"--------- METODOLOGIA BASEADA EM EXTRAÇÃO COM ResNet50 ---------\")\n","            train_vectors, valid_vectors = generate_vec_from_cnn('resnet50', base_dir)\n","            classification(train_vectors, valid_vectors, train_names, valid_names, train_classes, valid_classes, \"Classificação utilizando ResNet50 para extração de CARACTERÍSTICAS\")\n","    \n","    else: ##histogramas com equalização (melhor resultado)\n","        print(\"--------- METODOLOGIA BASEADA EM COMPARAÇÃO DE HISTOGRAMAS ---------\")\n","        train_histogram = generate_hist(train_images, dimensions, equalize=True)\n","        valid_histogram = generate_hist(valid_images, dimensions, equalize=True)\n","        classification(train_histogram, valid_histogram, train_names, valid_names, train_classes, valid_classes, \"Classificação de Histogramas (com equalização)\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyM/2IS89cU2mgHQJtKhOR3g","collapsed_sections":[],"name":"01_CNN.ipynb","provenance":[]},"interpreter":{"hash":"b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"},"kernelspec":{"display_name":"Python 3.8.8 64-bit ('base': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":2}
